{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA1x5l3QlWqC"
      },
      "source": [
        "# アリとハチの画像を分類するモデルを学習し、テストする\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRJbymzfozM5"
      },
      "source": [
        "本ファイルは、Google Colabでの実行を前提としています"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJN48pwclWqJ"
      },
      "source": [
        "# 事前準備\n",
        "\n",
        "セットアップのためのコード。「!」でターミナルコマンドを実行している。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/rin-nishikawa/internship.git\n",
        "%cd \"internship\"\n",
        "%cd \"1_image_classification\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWDnhY8Plo4P",
        "outputId": "9bf366b5-0c33-4f2f-a723-bcdc1f205d4d"
      },
      "outputs": [],
      "source": [
        "# make_folders_and_data_downloads.ipynbの中身を実行\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "以下のコードで、dataフォルダの中にhymenoptera_dataフォルダができる事を確認しよう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = \"./data/\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.mkdir(data_dir)\n",
        "\n",
        "if not os.path.exists(\"./weights/\"):\n",
        "    os.mkdir(\"./weights/\")\n",
        "\n",
        "# url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
        "# save_path = os.path.join(data_dir, \"imagenet_class_index.json\")\n",
        "\n",
        "# if not os.path.exists(save_path):\n",
        "#     urllib.request.urlretrieve(url, save_path)\n",
        "\n",
        "\n",
        "zip_path = os.path.join(data_dir, \"catdog.zip\")\n",
        "save_path = os.path.join(data_dir, \"catdog/\")\n",
        "# ZIPファイルを読み込み\n",
        "zip = zipfile.ZipFile(zip_path)\n",
        "zip.extractall(save_path)  # ZIPを解凍\n",
        "zip.close()  # ZIPファイルをクローズ\n",
        "# ZIPファイルを消去\n",
        "os.remove(zip_path)\n",
        "os.rename(\"./data/catdog/test/\", \"./data/catdog/val/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 初期設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Nk2_bfilWqJ"
      },
      "outputs": [],
      "source": [
        "# パッケージのimport\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsQFy7nflWqK"
      },
      "outputs": [],
      "source": [
        "# 乱数のシードを設定\n",
        "torch.manual_seed(1234)\n",
        "np.random.seed(1234)\n",
        "random.seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"使用デバイス：\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0wuE1LQlWqK"
      },
      "source": [
        "# DataSetを作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ――――演習１ここから――――"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PerlS6ilWqK"
      },
      "outputs": [],
      "source": [
        "# 入力画像の前処理をするクラス\n",
        "# 訓練時と推論時で処理が異なる\n",
        "\n",
        "\n",
        "class ImageTransform():\n",
        "    \"\"\"\n",
        "    画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
        "    画像のサイズをリサイズし、色を標準化する。\n",
        "    訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\n",
        "\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    resize : int\n",
        "        リサイズ先の画像の大きさ。\n",
        "    mean : (R, G, B)\n",
        "        各色チャネルの平均値。\n",
        "    std : (R, G, B)\n",
        "        各色チャネルの標準偏差。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, resize, mean, std):\n",
        "        self.data_transform = {\n",
        "            'train': transforms.Compose([\n",
        "                transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),  # データオーギュメンテーション\n",
        "                transforms.RandomHorizontalFlip(),  # データオーギュメンテーション\n",
        "                transforms.ToTensor(),  # テンソルに変換\n",
        "                transforms.Normalize(mean, std)  # 標準化\n",
        "            ]),\n",
        "            'val': transforms.Compose([\n",
        "                transforms.Resize(resize),  # リサイズ\n",
        "                transforms.CenterCrop(resize),  # 画像中央をresize×resizeで切り取り\n",
        "                transforms.ToTensor(),  # テンソルに変換\n",
        "                transforms.Normalize(mean, std)  # 標準化\n",
        "            ])\n",
        "        }\n",
        "\n",
        "    def __call__(self, img, phase='train'):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        phase : 'train' or 'val'\n",
        "            前処理のモードを指定。\n",
        "        \"\"\"\n",
        "        return self.data_transform[phase](img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "mnzGcMN_lWqL",
        "outputId": "f7d4f271-7c1f-4028-a5fe-9c1d1721218d"
      },
      "outputs": [],
      "source": [
        "# 訓練時の画像前処理の動作を確認\n",
        "# 実行するたびに処理結果の画像が変わる\n",
        "\n",
        "# 1. 画像読み込み\n",
        "image_file_path = './data/girl3.jpeg'\n",
        "img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n",
        "\n",
        "# 2. 元の画像の表示\n",
        "print(\"元画像表示\")\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "# 3. 画像の前処理と処理済み画像の表示\n",
        "size = 224\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "\n",
        "transform = ImageTransform(size, mean, std)\n",
        "img_transformed = transform(img, phase=\"train\")  # torch.Size([3, 224, 224])\n",
        "\n",
        "# (色、高さ、幅)を (高さ、幅、色)に変換し、0-1に値を制限して表示\n",
        "img_transformed = img_transformed.numpy().transpose((1, 2, 0))\n",
        "img_transformed = np.clip(img_transformed, 0, 1)\n",
        "print(\"変換後画像表示\")\n",
        "plt.imshow(img_transformed)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ――――演習１ここまで――――"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3gJ3XmJlWqM",
        "outputId": "23617ca5-dd0c-4bba-bfd7-e41fc270607e"
      },
      "outputs": [],
      "source": [
        "# アリとハチの画像へのファイルパスのリストを作成する\n",
        "\n",
        "\n",
        "def make_datapath_list(phase=\"train\"):\n",
        "    \"\"\"\n",
        "    データのパスを格納したリストを作成する。\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    phase : 'train' or 'val'\n",
        "        訓練データか検証データかを指定する\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    path_list : list\n",
        "        データへのパスを格納したリスト\n",
        "    \"\"\"\n",
        "\n",
        "    rootpath = \"./data/catdog/\"\n",
        "    target_path = osp.join(rootpath+phase+'/**/*.jpg')\n",
        "\n",
        "    path_list = []  # ここに格納する\n",
        "\n",
        "    # globを利用してサブディレクトリまでファイルパスを取得する\n",
        "    for path in glob.glob(target_path):\n",
        "        path_list.append(path)\n",
        "\n",
        "    return path_list\n",
        "\n",
        "\n",
        "# 実行\n",
        "train_list = make_datapath_list(phase=\"train\")\n",
        "val_list = make_datapath_list(phase=\"val\")\n",
        "\n",
        "print(train_list[1])\n",
        "print(val_list[1])\n",
        "print(len(train_list))\n",
        "print(len(val_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADiGymTSlWqM",
        "outputId": "02e26af1-1b30-4634-a5fb-0bf4901fc8a8"
      },
      "outputs": [],
      "source": [
        "# アリとハチの画像のDatasetを作成する\n",
        "\n",
        "\n",
        "class HymenopteraDataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    アリとハチの画像のDatasetクラス。PyTorchのDatasetクラスを継承。\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    file_list : リスト\n",
        "        画像のパスを格納したリスト\n",
        "    transform : object\n",
        "        前処理クラスのインスタンス\n",
        "    phase : 'train' or 'test'\n",
        "        学習か訓練かを設定する。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, file_list, transform=None, phase='train'):\n",
        "        self.file_list = file_list  # ファイルパスのリスト\n",
        "        self.transform = transform  # 前処理クラスのインスタンス\n",
        "        self.phase = phase  # train or valの指定\n",
        "\n",
        "    def __len__(self):\n",
        "        '''画像の枚数を返す'''\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''\n",
        "        前処理をした画像のTensor形式のデータとラベルを取得\n",
        "        '''\n",
        "\n",
        "        # index番目の画像をロード\n",
        "        img_path = self.file_list[index]\n",
        "        img = Image.open(img_path)  # [高さ][幅][色RGB]\n",
        "\n",
        "        # 画像の前処理を実施\n",
        "        img_transformed = self.transform(\n",
        "            img, self.phase)  # torch.Size([3, 224, 224])\n",
        "\n",
        "        # 画像のラベルをファイル名から抜き出す\n",
        "        if self.phase == \"train\":\n",
        "            label = img_path[20:24]\n",
        "        elif self.phase == \"val\":\n",
        "            label = img_path[18:22]\n",
        "\n",
        "        # ラベルを数値に変更する\n",
        "        if label == \"cats\":\n",
        "            label = 0\n",
        "        elif label == \"dogs\":\n",
        "            label = 1\n",
        "\n",
        "        return img_transformed, label\n",
        "\n",
        "\n",
        "# 実行\n",
        "train_dataset = HymenopteraDataset(\n",
        "    file_list=train_list, transform=ImageTransform(size, mean, std), phase='train')\n",
        "\n",
        "val_dataset = HymenopteraDataset(\n",
        "    file_list=val_list, transform=ImageTransform(size, mean, std), phase='val')\n",
        "\n",
        "# 動作確認\n",
        "index = 0\n",
        "print(train_list[index])\n",
        "print(train_dataset.__getitem__(index)[0].size())\n",
        "print(train_dataset.__getitem__(index)[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6M2pUtcklWqN"
      },
      "source": [
        "# DataLoaderを作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ――――演習２ここから――――"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TwF8UealWqN",
        "outputId": "8c0a5ed3-8a7d-407c-bb72-0cc4be80648f"
      },
      "outputs": [],
      "source": [
        "# ミニバッチのサイズを指定\n",
        "batch_size = 32\n",
        "\n",
        "# DataLoaderを作成\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 辞書型変数にまとめる\n",
        "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
        "\n",
        "# 動作確認\n",
        "batch_iterator = iter(dataloaders_dict[\"train\"])  # イテレータに変換\n",
        "inputs, labels = next(batch_iterator)  # 1番目の要素を取り出す\n",
        "print(inputs.size())\n",
        "print(labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ――――演習２ここまで――――"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDdKxowclWqN"
      },
      "source": [
        "# ネットワークモデルを作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ――――演習３ここから――――"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "350e40ad89fd4b289557201d12bd1878",
            "44a3efe233ad48699e9f59747f120f8d",
            "241cd1502c7c473ca0f525562f268c92",
            "96edb32a99d04f7d8bb9f161a699d4d3",
            "1b891dddf11343e696e5fd695c5a71df",
            "bc11034b13794c8db6b5dc2f4543932a",
            "d6b27aef63334910b4ec0b78b666684d",
            "af72d2b92986469d8abb55ab7b2ca180"
          ]
        },
        "id": "AsfGZ9B7lWqO",
        "outputId": "d7c303e3-b1e8-4229-ab39-c209cb820410"
      },
      "outputs": [],
      "source": [
        "# 学習済みのVGG-16モデルをロード\n",
        "# VGG-16モデルのインスタンスを生成\n",
        "use_pretrained = False  # 未学習パラメータを使用\n",
        "####演習####\n",
        "net = models.vgg16(pretrained=use_pretrained)\n",
        "\n",
        "# モデルのネットワーク構成を出力\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VGG16の最後の出力層の出力ユニットをアリとハチの2つに付け替える\n",
        "net.classifier[6] = nn.Linear(in_features=4096, out_features=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 訓練モードに設定\n",
        "net.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ――――演習３ここまで――――"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8rap7ISlWqO"
      },
      "source": [
        "# 損失関数を定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wiJCU6VlWqO"
      },
      "outputs": [],
      "source": [
        "# 損失関数の設定\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt3ziuoUlWqO"
      },
      "source": [
        "# 最適化手法を設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxkNa9LvlWqP",
        "outputId": "a480e08e-674e-45c3-c95d-b8c2ff848608"
      },
      "outputs": [],
      "source": [
        "####西川による変更####\n",
        "\n",
        "# # 転移学習で学習させるパラメータを、変数params_to_updateに格納する\n",
        "# params_to_update = []\n",
        "\n",
        "# # 学習させるパラメータ名\n",
        "# update_param_names = [\"classifier.6.weight\", \"classifier.6.bias\"]\n",
        "\n",
        "# # 学習させるパラメータ以外は勾配計算をなくし、変化しないように設定\n",
        "# for name, param in net.named_parameters():\n",
        "#     if name in update_param_names:\n",
        "#         param.requires_grad = True\n",
        "#         params_to_update.append(param)\n",
        "#         print(name)\n",
        "#     else:\n",
        "#         param.requires_grad = False\n",
        "\n",
        "# # params_to_updateの中身を確認\n",
        "# print(\"-----------\")\n",
        "# print(params_to_update)\n",
        "\n",
        "########\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDfKFIDglWqP"
      },
      "outputs": [],
      "source": [
        "# 最適化手法の設定\n",
        "\n",
        "####西川による修正####\n",
        "# optimizer = optim.SGD(params=params_to_update, lr=0.001, momentum=0.9)\n",
        "########\n",
        "\n",
        "optimizer = optim.SGD(params=net.parameters(), lr=0.001, momentum=0.9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ocQ2VbJlWqP"
      },
      "source": [
        "# 学習・検証を実施"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXgRLEXHlWqP"
      },
      "outputs": [],
      "source": [
        "# モデルを学習させる関数を作成\n",
        "\n",
        "\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, acc_history, num_epochs):\n",
        "\n",
        "    # GPUが使えるかを確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス：\", device)\n",
        "\n",
        "    # ネットワークをGPUへ\n",
        "    net.to(device)\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-------------')\n",
        "\n",
        "        # epochごとの学習と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モードに\n",
        "            else:\n",
        "                net.eval()   # モデルを検証モードに\n",
        "\n",
        "            epoch_loss = 0.0  # epochの損失和\n",
        "            epoch_corrects = 0  # epochの正解数\n",
        "\n",
        "            # 未学習時の検証性能を確かめるため、epoch=0の訓練は省略\n",
        "            if (epoch == 0) and (phase == 'train'):\n",
        "                continue\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "\n",
        "                inputs=inputs.to(device)\n",
        "                labels=labels.to(device)\n",
        "\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = net(inputs)\n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    # イタレーション結果の計算\n",
        "                    # lossの合計を更新\n",
        "                    epoch_loss += loss.item() * inputs.size(0)  \n",
        "                    # 正解数の合計を更新\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epochごとのlossと正解率を表示\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "            \n",
        "            if (epoch == 0) and (phase == 'val'):\n",
        "              continue\n",
        "            else:\n",
        "              acc_history[phase].append(epoch_acc.detach().cpu().numpy())\n",
        "    return acc_history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0cuPPsxlWqQ",
        "outputId": "202ca950-75c7-4236-b7e1-b7cd3e55b688"
      },
      "outputs": [],
      "source": [
        "# 学習・検証を実行する\n",
        "num_epochs=1\n",
        "acc_history = {'train': [], 'val': []}\n",
        "acc_history = train_model(net, dataloaders_dict, criterion, optimizer, acc_history, num_epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot()\n",
        "ax.plot(acc_history['train'], label='train')\n",
        "ax.plot(acc_history['val'], label='val')\n",
        "ax.legend()\n",
        "ax.set_ylim(0, 1)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NRfoFSZlWqQ"
      },
      "source": [
        "# テスト（推論）を実施"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "net.eval()  # 推論モードに設定\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ILSVRCのラベル情報をロードし辞書型変数を生成します\n",
        "ILSVRC_class_index = {'0': ['n02219486', 'cats'],'1': ['n02206856', 'dogs']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 出力結果からラベルを予測する後処理クラス\n",
        "class ILSVRCPredictor():\n",
        "    \"\"\"\n",
        "    ILSVRCデータに対するモデルの出力からラベルを求める。\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    class_index : dictionary\n",
        "            クラスindexとラベル名を対応させた辞書型変数。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, class_index):\n",
        "        self.class_index = class_index\n",
        "\n",
        "    def predict_max(self, out):\n",
        "        \"\"\"\n",
        "        確率最大のILSVRCのラベル名を取得する。\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        out : torch.Size([1, 2])\n",
        "            Netからの出力。\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        predicted_label_name : str\n",
        "            最も予測確率が高いラベルの名前\n",
        "        \"\"\"\n",
        "        print(\"アリであると推測：\"+str(out.detach().cpu().numpy()[0][0]))\n",
        "        print(\"ハチであると推測：\"+str(out.detach().cpu().numpy()[0][1]))\n",
        "        maxid = np.argmax(out.detach().cpu().numpy())\n",
        "\n",
        "        predicted_label_name = self.class_index[str(maxid)][1]\n",
        "\n",
        "        return predicted_label_name\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ――――演習４ここから――――"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ILSVRCPredictorのインスタンスを生成します\n",
        "predictor = ILSVRCPredictor(ILSVRC_class_index)\n",
        "\n",
        "# 入力画像を読み込む\n",
        "####演習####\n",
        "image_file_path = './data/b.jpeg'\n",
        "img = Image.open(image_file_path)  # [高さ][幅][色RGB]\n",
        "\n",
        "# 元の画像の表示\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "# 前処理の後、バッチサイズの次元を追加する\n",
        "resize = 224\n",
        "transform = ImageTransform(resize, mean, std)  # 前処理クラス作成\n",
        "img_transformed = transform(img)  # torch.Size([3, 224, 224])\n",
        "inputs = img_transformed.unsqueeze_(0)  # torch.Size([1, 3, 224, 224])\n",
        "inputs=inputs.to(device)\n",
        "\n",
        "# モデルに入力し、モデル出力をラベルに変換する\n",
        "out = net(inputs)  # torch.Size([1, 1000])\n",
        "result = predictor.predict_max(out)\n",
        "\n",
        "# 予測結果を出力する\n",
        "print(\"入力画像の予測結果：\", result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ――――演習４ここまで――――"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 参考\n",
        "https://github.com/YutaroOgawa/pytorch_advanced , (参照 2023-10-26)  \n",
        "小川雄太郎. つくりながら学ぶ! PyTorchによる発展ディープラーニング. マイナビ, 2019"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "1-3_transfer_learning_on_GoogleColab.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1b891dddf11343e696e5fd695c5a71df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "241cd1502c7c473ca0f525562f268c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc11034b13794c8db6b5dc2f4543932a",
            "max": 553433881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b891dddf11343e696e5fd695c5a71df",
            "value": 553433881
          }
        },
        "350e40ad89fd4b289557201d12bd1878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_241cd1502c7c473ca0f525562f268c92",
              "IPY_MODEL_96edb32a99d04f7d8bb9f161a699d4d3"
            ],
            "layout": "IPY_MODEL_44a3efe233ad48699e9f59747f120f8d"
          }
        },
        "44a3efe233ad48699e9f59747f120f8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96edb32a99d04f7d8bb9f161a699d4d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af72d2b92986469d8abb55ab7b2ca180",
            "placeholder": "​",
            "style": "IPY_MODEL_d6b27aef63334910b4ec0b78b666684d",
            "value": " 528M/528M [00:14&lt;00:00, 39.5MB/s]"
          }
        },
        "af72d2b92986469d8abb55ab7b2ca180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc11034b13794c8db6b5dc2f4543932a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6b27aef63334910b4ec0b78b666684d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
